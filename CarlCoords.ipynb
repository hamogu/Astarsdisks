{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is just that - a list of notes. It can be used ot reconstruct all lists and tables from scratch, but in practice I don't want to do that every time. Instead, I can load the intermediate data tables for most purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.table import Table, QTable\n",
    "from astropy import table\n",
    "from astropy.coordinates import SkyCoord, Distance, Latitude, Longitude, Distance\n",
    "from astropy.time import Time\n",
    "\n",
    "from astroquery.simbad import Simbad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = Table.read('targetnames.txt', format='ascii.no_header', delimiter='|', names=['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TargetSimbad = Simbad()\n",
    "TargetSimbad.add_votable_fields('propermotions', 'distance', 'parallax', 'flux(B)', 'flux(V)', 'rv_value', 'sp')\n",
    "TargetSimbad.add_votable_fields('ra(2;A;ICRS;J2000;2000)', 'dec(2;D;ICRS;J2000;2000)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_download = TargetSimbad.query_objects(names['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = table.hstack([names, targets_download], join_type='exact')\n",
    "# translate units to astropy\n",
    "for col in targets.colnames:\n",
    "    if str(targets[col].unit) == '\"h:m:s\"':\n",
    "        targets[col] = Longitude(targets[col], unit=u.hourangle)\n",
    "    elif str(targets[col].unit) == '\"d:m:s\"':\n",
    "        targets[col] = Latitude(targets[col], unit=u.deg)\n",
    "# For Distance_distance, units are in separate column \n",
    "        \n",
    "targets = QTable(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets['Distance_unit'][targets['Distance_unit'] == ''] = 'pc'\n",
    "targets['distance'] = u.Quantity([row['Distance_distance'] * u.Unit(row['Distance_unit']) for row in targets])\n",
    "# Some distances suddenly become 0, where the input was masked. We deal with those next.\n",
    "\n",
    "\n",
    "# Distances are typically taken from GAIA, but some bright stars are missing. \n",
    "# For those, we calculate the distance from the parallax (from HIPPARCOS)\n",
    "ind = targets['Distance_distance'].mask\n",
    "ind = targets['Distance_perr'].mask\n",
    "targets['distance'][ind] = targets['PLX_VALUE'].to(u.pc, equivalencies=u.parallax())[ind]\n",
    "targets['Distance_method'][ind] = 'paral'\n",
    "targets['Distance_perr'][ind] = ((targets['PLX_VALUE'] - targets['PLX_ERROR']).to(u.pc, equivalencies=u.parallax()) \n",
    "                                 - targets['distance'])[ind]\n",
    "targets['Distance_merr'][ind] = ((targets['PLX_VALUE'] + targets['PLX_ERROR']).to(u.pc, equivalencies=u.parallax()) \n",
    "                                 - targets['distance'])[ind]\n",
    "targets['Distance_bibcode'][ind] = targets['PLX_BIBCODE'][ind]\n",
    "# finally: Clean up non-quantity input columns\n",
    "targets.remove_columns(['Distance_distance', 'Distance_unit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert byte objects into strings, because we can't save byte objetcs to fits later\n",
    "for c in targets.colnames:\n",
    "    if targets[c].dtype == np.object:\n",
    "        targets[c] = [s.decode() for s in targets[c]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets['coord'] = SkyCoord(ra=targets['RA_2_A_ICRS_J2000_2000'],\n",
    "                            dec=targets['DEC_2_D_ICRS_J2000_2000'],\n",
    "                            distance=targets['distance'],\n",
    "                            pm_ra_cosdec=targets['PMRA'],\n",
    "                            pm_dec=targets['PMDEC'],\n",
    "                            frame='icrs', obstime='J2000', equinox='J2000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets.write('targets.csv', format='ascii.ecsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: I doubt that the proper motion in the table is serialized correctly, but can always reconstruct\n",
    "# from the other columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other source properties\n",
    "\n",
    "search.py in this directory pulls in other properties fomr e.g. GAIA and Vizier for mass, bolometric luminosity etc. Eventually, I need that, but first I continue with the X-ray analysis and leave this chapter empty."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List of datasets and properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import re\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def header_to_table(filename, ext=0):\n",
    "    header = fits.getheader(filename, ext=ext)\n",
    "    h = {k: [header[k]] for k in header.keys()}\n",
    "    h['filename'] = [filename]\n",
    "    h['obsdirname'] = [os.path.basename(filename)]\n",
    "    # The following can have different shapes, which prevents merging\n",
    "    for key in ['HISTORY', 'COMMENT']:\n",
    "         if key in h:\n",
    "            del h[key]\n",
    "    return Table(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablist = []\n",
    "for f in glob('data/Chandra/*/repro/*evt2*'):\n",
    "    tablist.append(header_to_table(f, ext=1))\n",
    "chandra_data = table.vstack(tablist)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chandra_data['pnt_coords'] = SkyCoord(ra=chandra_data['RA_PNT'], \n",
    "                                      dec=chandra_data['DEC_PNT'],\n",
    "                                      unit=(u.deg, u.deg))\n",
    "\n",
    "idx, d2d, d3d = chandra_data['pnt_coords'].match_to_catalog_sky(targets['coord'])\n",
    "\n",
    "chandra_data['target'] = targets['target'][idx]\n",
    "chandra_data['target_coord'] = targets['coord'][idx]\n",
    "chandra_data['distance_from_pnt'] = d2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ciao_contrib.region.check_fov import FOVFiles\n",
    "\n",
    "chandra_data['FOV'] = False\n",
    "for row in chandra_data: \n",
    "    my_obs = FOVFiles(row['filename'].replace('evt2', 'fov1'))\n",
    "    ii = my_obs.inside(row['target_coord'].ra.deg, row['target_coord'].dec.deg)\n",
    "    if len(ii) > 0:\n",
    "        row['FOV'] = True\n",
    "        \n",
    "# Only keep those sources that have our target in FOV.\n",
    "# Need to check for XMM, too, once I include that.\n",
    "chandra_data = chandra_data[chandra_data['FOV']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chandra_data['target', 'distance_from_pnt', 'FOV', 'TELESCOP', 'OBS_ID', 'INSTRUME', 'GRATING', 'EXPOSURE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_image_in_slew_match(obsid, targets):\n",
    "    '''Step throu all band 8 slew exposure maps.\n",
    "    For each map, check if one of the target objects i in the exposure map,\n",
    "    and if so, if the exposure time is > 0 (i.e. it truely is observed).\n",
    "    If an object is part of more than one image, select he image where ii\n",
    "    is further away form the edge.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    expmapout : list of strings\n",
    "        filename of a expmap file that contains a target\n",
    "    '''\n",
    "    d = []\n",
    "    expmaps = []\n",
    "    objects = []\n",
    "    for expmap in glob('data/XMM/' + obsid + '/*EXPMAP8???.ds'): # band 8 is all energies\n",
    "        with fits.open(expmap) as hdus:\n",
    "            wcs = WCS(hdus[0].header)\n",
    "            dat = hdus[0].data\n",
    "        y, x = wcs.all_world2pix(targets['coord'].ra, targets['coord'].dec, 0, ra_dec_order=True)\n",
    "        object_in_image = (x > 0) & (x < dat.shape[0]) & (y > 0) & (y < dat.shape[1])\n",
    "        for ind in object_in_image.nonzero()[0]:\n",
    "            # Check exposure time is > 0, i.e. object is in slew path\n",
    "            if dat[int(x[ind]), int(y[ind])] > 0:\n",
    "                # Get distance from image center\n",
    "                d.append((x[ind] - dat.shape[0]/2)**2 + (y[ind] - dat.shape[1]/2)**2)\n",
    "                expmaps.append(expmap)\n",
    "                objects.append(targets['target'][ind])\n",
    "    # Now select the best images if an object is in more than one \n",
    "    # (image overlap at the edges, but this is really the same data)\n",
    "    expmapout = []\n",
    "    # Some comparisons are eaiser ot write if it's all turned into numpy arrays\n",
    "    objects = np.array(objects)\n",
    "    d = np.array(d)\n",
    "    expmaps = np.array(expmaps)\n",
    "    for o in set(objects):\n",
    "        oind = objects == o\n",
    "        minind = np.argmin(d[oind])\n",
    "        expmapout.append(expmaps[oind][minind])\n",
    "    return expmapout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tablist = []\n",
    "\n",
    "for d in glob('data/XMM/*'):\n",
    "    obsid = os.path.basename(d)\n",
    "    if re.match('^[0-8]', obsid):\n",
    "        infiles = glob(d + '/images/*')\n",
    "        if len(infiles) == 0:\n",
    "            infiles = glob(d + '/rgs/pi*fit')\n",
    "        if len(infiles) > 0:\n",
    "            tablist.append(header_to_table(infiles[0]))\n",
    "        else:\n",
    "            # I downloaded these ObsIDS, but they seem not to contain any data.\n",
    "            # I also can't find them in a \"by obsid\" search in the XSA.\n",
    "            # Might be aborted or cal with unusual setups?\n",
    "            print('No data found:', obsid)\n",
    "    elif obsid.startswith('9'):\n",
    "        # slew\n",
    "        expfiles = find_image_in_slew_match(obsid, targets)\n",
    "        if len(expfiles) == 0 :\n",
    "            print('Slew with no target in path:', obsid)\n",
    "        for e in expfiles:\n",
    "            tablist.append(header_to_table(e))\n",
    "    else:\n",
    "        # Not XMM data, e.g. filename of a script that's left over in directory\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xmm_data = table.vstack(tablist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to remove mixin coordinate column before stacking for astropy < 4.2\n",
    "chandra_data.remove_columns(['pnt_coords', 'target_coord'])\n",
    "all_data = table.vstack([chandra_data, xmm_data])\n",
    "# Select columns to keep. This includes Chandr and XMM specific keywords, but most keywords\n",
    "# are OGIP standard and appear in both missions.\n",
    "all_data.keep_columns(['TELESCOP', 'OBS_ID', 'INSTRUME', 'GRATING', 'EXPOSURE',\n",
    "    'TITLE', 'DS_IDENT', 'DETNAM', 'EXP_ID', 'EXPIDSTR',\n",
    "    'FILTER', 'DATAMODE', 'DATE-OBS', 'DATE-END', 'OBS_MODE', 'OBSERVER', 'OBJECT', \n",
    "    'RA_OBJ', 'DEC_OBJ', 'RA_NOM', 'DEC_NOM', 'RA_PNT', 'DEC_PNT', 'PA_PNT', 'ROLL_PNT',\n",
    "    'RA_NOM', 'DEC_NOM', 'ROLL_NOM', 'EXPOSURE',\n",
    "                       'SIM_X', 'SIM_Y', 'SIM_Z', 'DY_AVG', 'DZ_AVG', 'DTH_AVG',\n",
    "    'filename', 'obsdirname'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data['pnt_coords'] = SkyCoord(ra=all_data['RA_PNT'], \n",
    "                                      dec=all_data['DEC_PNT'],\n",
    "                                      unit=(u.deg, u.deg))\n",
    "\n",
    "idx, d2d, d3d = all_data['pnt_coords'].match_to_catalog_sky(targets['coord'])\n",
    "\n",
    "all_data['target'] = targets['target'][idx]\n",
    "all_data['target_coord'] = targets['coord'][idx]\n",
    "all_data['distance_from_pnt'] = d2d\n",
    "# There are a few XMM calibration observations with mismatches between requested\n",
    "# and true pointing that happend to be too far away to be useful here.\n",
    "all_data = all_data[all_data['distance_from_pnt'] < 1 * u.deg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutouts and preview checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ciao_contrib.runtool as rt\n",
    "from coords.chandra import cel_to_chandra\n",
    "from astropy.time import Time\n",
    "\n",
    "row = all_data[all_data['TELESCOP'] == 'CHANDRA'][0]\n",
    "# Many of the objects have high proper motion\n",
    "target_at_obs = row['target_coord'].apply_space_motion(new_obstime=Time(row['DATE-OBS']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chan_coords = cel_to_chandra({k: row[k] for k in row.colnames}, target_at_obs.ra.deg, target_at_obs.dec.deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.wcs import WCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdus = fits.open(\"data/XMM/0843151001/mos/3642_0843151001_EMOS1_S001_ImagingEvts.ds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcs = WCS(hdus[1].header, keysel=['pixel'], naxis=['celestial'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evts = Table(hdus[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, x_edges, y_edges = np.histogram2d(evts['X'], evts['Y'], bins=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regions import CircleSkyRegion, CirclePixelRegion\n",
    "from astropy.coordinates import Angle, SkyCoord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = CircleSkyRegion(SkyCoord('19:30', '51:40', unit=(u.hourangle, u.deg)), Angle(.1 * u.deg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = region.to_pixel(wcs).as_artist(edgecolor='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection=wcs, aspect=1)\n",
    "ax.imshow(h.T, extent=[x_edges[0], x_edges[-1], y_edges[0], y_edges[-1]])\n",
    "ax.add_artist(artist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
